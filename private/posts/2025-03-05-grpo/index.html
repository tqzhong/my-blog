<!doctype html><html lang=en dir=auto><a href=https://yourpersonalwebsite.com target=_blank><head><script src=https://cdn.jsdelivr.net/npm/fuse.js/dist/fuse.min.js></script><link rel=stylesheet href=https://unpkg.com/@waline/client@v3/dist/waline.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js></script><script>hljs.initHighlightingOnLoad()</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/plugins/line-numbers.min.js></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="noindex, nofollow"><title>GRPO From Scratch | Rs' Log</title>
<meta name=keywords content="AI,NLP,LLM,RL"><meta name=description content="简介
本篇博客基于Andriy Burkov的grpo开源代码，简单跑通GRPO的完整流程。使用的GPU资源为1张3090（24G）。原作者代码见：GRPO_From-Scratch以及GRPO_Qwen-0_5_Instruct。注：原作者使用8张80G A100完成实验。
GRPO
GRPO算法原理见alg-grpo，原作者在这块的实现基本遵从DeepSeek技术报告中的损失公式，后面代码处详细展开。

$$
\begin{align*}
\mathcal{J}_{\text{GRPO}}(\theta) &= \mathbb{E}\left[q \sim P(Q), \{o_i\}_{i=1}^G \sim \pi_{\theta_{\text{old}}}(O|q)\right]\\
&=\frac{1}{G} \sum_{i=1}^G \left\{
\min \left[ 
\frac{\pi_{\theta}(o_i | q)}{\pi_{\theta_{\text{old}}}(o_i | q)} A_i, 
\text{clip}\left( \frac{\pi_{\theta}(o_i | q)}{\pi_{\theta_{\text{old}}}(o_i | q)}, 1 - \epsilon, 1 + \epsilon \right) A_i 
\right] 
- \beta \mathbb D_{\text{KL}}[\pi_{\theta} \| \pi_{\text{ref}}]
\right\}\\
&=\frac{1}{G} \sum_{i=1}^G\frac{1}{\vert o_i\vert}\sum_{t=1}^{\vert o_i\vert}\left\{\min\left[\frac{\pi_\theta(o_{i,t}\vert q,o_{i,< t})}{\pi_{\theta_{old}}(o_{i,t}\vert q, o_{i,< t})}\hat A_{i,t},\ \text{clip}\left(\frac{\pi_\theta(o_{i,t}\vert q,o_{i,< t})}{\pi_{\theta_{old}}(o_{i,t}\vert q,o_{i, < t})},1-\epsilon,1+\epsilon\right)\hat A_{i,t}\right] - \beta\mathbb D_{KL}[\pi_\theta\Vert\pi_{\text{ref}}]\right\}
\end{align*}
$$


$$
D_{\text{KL}}(\pi_{\theta} \| \pi_{\text{ref}}) = 
\frac{\pi_{\text{ref}}(o_{i, t} | q, o_{i, < t})}{\pi_{\theta}(o_{i, t} | q, o_{i, < t})} 
- \log \frac{\pi_{\text{ref}}(o_{i, t} | q, o_{i, < t})}{\pi_{\theta}(o_{i, t} | q, o_{i, < t})} - 1,
$$


$$
\hat A_{i,t}=A_i = \frac{r_i - \text{mean}(\{r_1, r_2, \cdots, r_G\})}{\text{std}(\{r_1, r_2, \cdots, r_G\})}.
$$

GRPO算法出自文章DeepSeekMath (2024)，其中KL散度的计算采用了Approximating KL Divergence中的无偏估计方法，即$\mathbb D_{KL}(q\Vert p)=r-1-\log r$，其中$r=\log\frac{p(x)}{q(x)}$，该估计相比$-\log r$具有更小的方差，比$\frac{1}{2}(\log r)^2$具有更小的偏差（无偏）。"><meta name=author content="Rs"><link rel=canonical href=https://tqzhong.github.io/my-blog/posts/2025-03-05-grpo/><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css><link crossorigin=anonymous href=/my-blog/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/my-blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon type=image/x-icon sizes=48x48 href=images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=images/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=images/favicon-32x32.png><link rel=apple-touch-icon href=images/apple-touch-icon.png><link rel=icon sizes=512x512 href=images/android-chrome-512x512.png type=image/png><link rel=icon sizes=192x192 href=images/android-chrome-192x192.png type=image/png><link rel=mask-icon href=https://tqzhong.github.io/my-blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://tqzhong.github.io/my-blog/posts/2025-03-05-grpo/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href="/my-blog/css/custom.css?v=1.7"></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},svg:{fontCache:"global"}}</script><nav class=nav><div class=logo-logo-switches><div class=logo><a href=https://tqzhong.github.io/my-blog/ accesskey=h title="Rs' Log (Alt + H)">Rs' Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch></ul></div></div></div><ul id=menu><li><a href=https://tqzhong.github.io/my-blog/ title=Posts><span>Posts</span></a></li><li><a href=https://tqzhong.github.io/my-blog/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://tqzhong.github.io/my-blog/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://tqzhong.github.io/my-blog/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://tqzhong.github.io/my-blog/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://tqzhong.github.io/my-blog/faq/ title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>GRPO From Scratch</h1><div class=post-meta><i class="fas fa-calendar-alt blog-meta-icon"></i>&nbsp;2025-03-05 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <i class="fas fa-clock blog-meta-icon"></i>&nbsp;22 min &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <i class="fas fa-user blog-meta-icon"></i>&nbsp;Rs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <i class="fas fa-eye blog-meta-icon"></i>&nbsp;<span id=view-counter></span>
<script src=https://cdn.jsdelivr.net/npm/leancloud-storage@4.12.0/dist/av-min.js></script><script>AV.initialize("AokLJzaIvwVNJW0b2F0YTLLy-MdYXbMMI","fwZpRfBG259O3LscJFPW3ViH"),loadViewCount(location.pathname,"view-counter");var hasViewCounted=!1;function loadViewCount(e,t){if(hasViewCounted)return;hasViewCounted=!0;var s,n=document.getElementById(t),o=localStorage.getItem("view-count-"+e);o?n.innerText=o:n.innerText="0",s=new AV.Query("Counter"),s.equalTo("url",e),s.find().then(t=>{if(t.length>0){var s,i,a,o=t[0];o.increment("views",1),o.save(),i=o.get("views"),n.innerText=i,localStorage.setItem("view-count-"+e,i)}else a=AV.Object.extend("Counter"),s=new a,s.set("url",e),s.set("views",1),s.save().then(()=>{n.innerText="1",localStorage.setItem("view-count-"+e,1)})}).catch(function(e){console.error("error:",e)})}</script></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e7%ae%80%e4%bb%8b aria-label=简介>简介</a></li><li><a href=#grpo aria-label=GRPO>GRPO</a></li><li><a href=#%e4%bb%a3%e7%a0%81 aria-label=代码>代码</a></li><li><a href=#%e5%8d%95%e5%8d%a1%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c aria-label=单卡实验结果>单卡实验结果</a></li><li><a href=#%e5%8d%95%e5%8d%a1%e5%ae%9e%e9%aa%8c%e5%b0%8f%e7%bb%93 aria-label=单卡实验小结>单卡实验小结</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h3 id=简介>简介<a hidden class=anchor aria-hidden=true href=#简介>#</a></h3><p>本篇博客基于Andriy Burkov的grpo开源代码，简单跑通GRPO的完整流程。使用的GPU资源为1张3090（24G）。原作者代码见：<a href=https://github.com/aburkov/theLMbook/blob/main/GRPO_From_Scratch_Multi_GPU_DataParallel_Qwen_2_5_1_5B_Instruct.ipynb class=entityLink>GRPO_From-Scratch</a>以及<a href=https://github.com/aburkov/theLMbook/blob/main/GRPO_Qwen_0_5_Instruct.ipynb class=entityLink>GRPO_Qwen-0_5_Instruct</a>。注：原作者使用8张80G A100完成实验。</p><h3 id=grpo>GRPO<a hidden class=anchor aria-hidden=true href=#grpo>#</a></h3><p>GRPO算法原理见<a href=https://matrixai.online/my-blog/posts/2025-01-27-deepseek-r1/#311-reinforcement-learning-algorithm class=entityLink>alg-grpo</a>，原作者在这块的实现基本遵从DeepSeek技术报告中的损失公式，后面代码处详细展开。</p><div class=scroll-container>$$
\begin{align*}
\mathcal{J}_{\text{GRPO}}(\theta) &= \mathbb{E}\left[q \sim P(Q), \{o_i\}_{i=1}^G \sim \pi_{\theta_{\text{old}}}(O|q)\right]\\
&=\frac{1}{G} \sum_{i=1}^G \left\{
\min \left[
\frac{\pi_{\theta}(o_i | q)}{\pi_{\theta_{\text{old}}}(o_i | q)} A_i,
\text{clip}\left( \frac{\pi_{\theta}(o_i | q)}{\pi_{\theta_{\text{old}}}(o_i | q)}, 1 - \epsilon, 1 + \epsilon \right) A_i
\right]
- \beta \mathbb D_{\text{KL}}[\pi_{\theta} \| \pi_{\text{ref}}]
\right\}\\
&=\frac{1}{G} \sum_{i=1}^G\frac{1}{\vert o_i\vert}\sum_{t=1}^{\vert o_i\vert}\left\{\min\left[\frac{\pi_\theta(o_{i,t}\vert q,o_{i,< t})}{\pi_{\theta_{old}}(o_{i,t}\vert q, o_{i,< t})}\hat A_{i,t},\ \text{clip}\left(\frac{\pi_\theta(o_{i,t}\vert q,o_{i,< t})}{\pi_{\theta_{old}}(o_{i,t}\vert q,o_{i, < t})},1-\epsilon,1+\epsilon\right)\hat A_{i,t}\right] - \beta\mathbb D_{KL}[\pi_\theta\Vert\pi_{\text{ref}}]\right\}
\end{align*}
$$</div><div class=scroll-container>$$
D_{\text{KL}}(\pi_{\theta} \| \pi_{\text{ref}}) =
\frac{\pi_{\text{ref}}(o_{i, t} | q, o_{i, < t})}{\pi_{\theta}(o_{i, t} | q, o_{i, < t})}
- \log \frac{\pi_{\text{ref}}(o_{i, t} | q, o_{i, < t})}{\pi_{\theta}(o_{i, t} | q, o_{i, < t})} - 1,
$$</div><div class=scroll-container>$$
\hat A_{i,t}=A_i = \frac{r_i - \text{mean}(\{r_1, r_2, \cdots, r_G\})}{\text{std}(\{r_1, r_2, \cdots, r_G\})}.
$$</div><p>GRPO算法出自文章<a href=https://arxiv.org/abs/2402.03300 class=entityLink>DeepSeekMath (2024)</a>，其中KL散度的计算采用了<a href=http://joschu.net/blog/kl-approx.html class=entityLink>Approximating KL Divergence</a>中的无偏估计方法，即$\mathbb D_{KL}(q\Vert p)=r-1-\log r$，其中$r=\log\frac{p(x)}{q(x)}$，该估计相比$-\log r$具有更小的方差，比$\frac{1}{2}(\log r)^2$具有更小的偏差（无偏）。</p><h3 id=代码>代码<a hidden class=anchor aria-hidden=true href=#代码>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span><span class=lnt>252
</span><span class=lnt>253
</span><span class=lnt>254
</span><span class=lnt>255
</span><span class=lnt>256
</span><span class=lnt>257
</span><span class=lnt>258
</span><span class=lnt>259
</span><span class=lnt>260
</span><span class=lnt>261
</span><span class=lnt>262
</span><span class=lnt>263
</span><span class=lnt>264
</span><span class=lnt>265
</span><span class=lnt>266
</span><span class=lnt>267
</span><span class=lnt>268
</span><span class=lnt>269
</span><span class=lnt>270
</span><span class=lnt>271
</span><span class=lnt>272
</span><span class=lnt>273
</span><span class=lnt>274
</span><span class=lnt>275
</span><span class=lnt>276
</span><span class=lnt>277
</span><span class=lnt>278
</span><span class=lnt>279
</span><span class=lnt>280
</span><span class=lnt>281
</span><span class=lnt>282
</span><span class=lnt>283
</span><span class=lnt>284
</span><span class=lnt>285
</span><span class=lnt>286
</span><span class=lnt>287
</span><span class=lnt>288
</span><span class=lnt>289
</span><span class=lnt>290
</span><span class=lnt>291
</span><span class=lnt>292
</span><span class=lnt>293
</span><span class=lnt>294
</span><span class=lnt>295
</span><span class=lnt>296
</span><span class=lnt>297
</span><span class=lnt>298
</span><span class=lnt>299
</span><span class=lnt>300
</span><span class=lnt>301
</span><span class=lnt>302
</span><span class=lnt>303
</span><span class=lnt>304
</span><span class=lnt>305
</span><span class=lnt>306
</span><span class=lnt>307
</span><span class=lnt>308
</span><span class=lnt>309
</span><span class=lnt>310
</span><span class=lnt>311
</span><span class=lnt>312
</span><span class=lnt>313
</span><span class=lnt>314
</span><span class=lnt>315
</span><span class=lnt>316
</span><span class=lnt>317
</span><span class=lnt>318
</span><span class=lnt>319
</span><span class=lnt>320
</span><span class=lnt>321
</span><span class=lnt>322
</span><span class=lnt>323
</span><span class=lnt>324
</span><span class=lnt>325
</span><span class=lnt>326
</span><span class=lnt>327
</span><span class=lnt>328
</span><span class=lnt>329
</span><span class=lnt>330
</span><span class=lnt>331
</span><span class=lnt>332
</span><span class=lnt>333
</span><span class=lnt>334
</span><span class=lnt>335
</span><span class=lnt>336
</span><span class=lnt>337
</span><span class=lnt>338
</span><span class=lnt>339
</span><span class=lnt>340
</span><span class=lnt>341
</span><span class=lnt>342
</span><span class=lnt>343
</span><span class=lnt>344
</span><span class=lnt>345
</span><span class=lnt>346
</span><span class=lnt>347
</span><span class=lnt>348
</span><span class=lnt>349
</span><span class=lnt>350
</span><span class=lnt>351
</span><span class=lnt>352
</span><span class=lnt>353
</span><span class=lnt>354
</span><span class=lnt>355
</span><span class=lnt>356
</span><span class=lnt>357
</span><span class=lnt>358
</span><span class=lnt>359
</span><span class=lnt>360
</span><span class=lnt>361
</span><span class=lnt>362
</span><span class=lnt>363
</span><span class=lnt>364
</span><span class=lnt>365
</span><span class=lnt>366
</span><span class=lnt>367
</span><span class=lnt>368
</span><span class=lnt>369
</span><span class=lnt>370
</span><span class=lnt>371
</span><span class=lnt>372
</span><span class=lnt>373
</span><span class=lnt>374
</span><span class=lnt>375
</span><span class=lnt>376
</span><span class=lnt>377
</span><span class=lnt>378
</span><span class=lnt>379
</span><span class=lnt>380
</span><span class=lnt>381
</span><span class=lnt>382
</span><span class=lnt>383
</span><span class=lnt>384
</span><span class=lnt>385
</span><span class=lnt>386
</span><span class=lnt>387
</span><span class=lnt>388
</span><span class=lnt>389
</span><span class=lnt>390
</span><span class=lnt>391
</span><span class=lnt>392
</span><span class=lnt>393
</span><span class=lnt>394
</span><span class=lnt>395
</span><span class=lnt>396
</span><span class=lnt>397
</span><span class=lnt>398
</span><span class=lnt>399
</span><span class=lnt>400
</span><span class=lnt>401
</span><span class=lnt>402
</span><span class=lnt>403
</span><span class=lnt>404
</span><span class=lnt>405
</span><span class=lnt>406
</span><span class=lnt>407
</span><span class=lnt>408
</span><span class=lnt>409
</span><span class=lnt>410
</span><span class=lnt>411
</span><span class=lnt>412
</span><span class=lnt>413
</span><span class=lnt>414
</span><span class=lnt>415
</span><span class=lnt>416
</span><span class=lnt>417
</span><span class=lnt>418
</span><span class=lnt>419
</span><span class=lnt>420
</span><span class=lnt>421
</span><span class=lnt>422
</span><span class=lnt>423
</span><span class=lnt>424
</span><span class=lnt>425
</span><span class=lnt>426
</span><span class=lnt>427
</span><span class=lnt>428
</span><span class=lnt>429
</span><span class=lnt>430
</span><span class=lnt>431
</span><span class=lnt>432
</span><span class=lnt>433
</span><span class=lnt>434
</span><span class=lnt>435
</span><span class=lnt>436
</span><span class=lnt>437
</span><span class=lnt>438
</span><span class=lnt>439
</span><span class=lnt>440
</span><span class=lnt>441
</span><span class=lnt>442
</span><span class=lnt>443
</span><span class=lnt>444
</span><span class=lnt>445
</span><span class=lnt>446
</span><span class=lnt>447
</span><span class=lnt>448
</span><span class=lnt>449
</span><span class=lnt>450
</span><span class=lnt>451
</span><span class=lnt>452
</span><span class=lnt>453
</span><span class=lnt>454
</span><span class=lnt>455
</span><span class=lnt>456
</span><span class=lnt>457
</span><span class=lnt>458
</span><span class=lnt>459
</span><span class=lnt>460
</span><span class=lnt>461
</span><span class=lnt>462
</span><span class=lnt>463
</span><span class=lnt>464
</span><span class=lnt>465
</span><span class=lnt>466
</span><span class=lnt>467
</span><span class=lnt>468
</span><span class=lnt>469
</span><span class=lnt>470
</span><span class=lnt>471
</span><span class=lnt>472
</span><span class=lnt>473
</span><span class=lnt>474
</span><span class=lnt>475
</span><span class=lnt>476
</span><span class=lnt>477
</span><span class=lnt>478
</span><span class=lnt>479
</span><span class=lnt>480
</span><span class=lnt>481
</span><span class=lnt>482
</span><span class=lnt>483
</span><span class=lnt>484
</span><span class=lnt>485
</span><span class=lnt>486
</span><span class=lnt>487
</span><span class=lnt>488
</span><span class=lnt>489
</span><span class=lnt>490
</span><span class=lnt>491
</span><span class=lnt>492
</span><span class=lnt>493
</span><span class=lnt>494
</span><span class=lnt>495
</span><span class=lnt>496
</span><span class=lnt>497
</span><span class=lnt>498
</span><span class=lnt>499
</span><span class=lnt>500
</span><span class=lnt>501
</span><span class=lnt>502
</span><span class=lnt>503
</span><span class=lnt>504
</span><span class=lnt>505
</span><span class=lnt>506
</span><span class=lnt>507
</span><span class=lnt>508
</span><span class=lnt>509
</span><span class=lnt>510
</span><span class=lnt>511
</span><span class=lnt>512
</span><span class=lnt>513
</span><span class=lnt>514
</span><span class=lnt>515
</span><span class=lnt>516
</span><span class=lnt>517
</span><span class=lnt>518
</span><span class=lnt>519
</span><span class=lnt>520
</span><span class=lnt>521
</span><span class=lnt>522
</span><span class=lnt>523
</span><span class=lnt>524
</span><span class=lnt>525
</span><span class=lnt>526
</span><span class=lnt>527
</span><span class=lnt>528
</span><span class=lnt>529
</span><span class=lnt>530
</span><span class=lnt>531
</span><span class=lnt>532
</span><span class=lnt>533
</span><span class=lnt>534
</span><span class=lnt>535
</span><span class=lnt>536
</span><span class=lnt>537
</span><span class=lnt>538
</span><span class=lnt>539
</span><span class=lnt>540
</span><span class=lnt>541
</span><span class=lnt>542
</span><span class=lnt>543
</span><span class=lnt>544
</span><span class=lnt>545
</span><span class=lnt>546
</span><span class=lnt>547
</span><span class=lnt>548
</span><span class=lnt>549
</span><span class=lnt>550
</span><span class=lnt>551
</span><span class=lnt>552
</span><span class=lnt>553
</span><span class=lnt>554
</span><span class=lnt>555
</span><span class=lnt>556
</span><span class=lnt>557
</span><span class=lnt>558
</span><span class=lnt>559
</span><span class=lnt>560
</span><span class=lnt>561
</span><span class=lnt>562
</span><span class=lnt>563
</span><span class=lnt>564
</span><span class=lnt>565
</span><span class=lnt>566
</span><span class=lnt>567
</span><span class=lnt>568
</span><span class=lnt>569
</span><span class=lnt>570
</span><span class=lnt>571
</span><span class=lnt>572
</span><span class=lnt>573
</span><span class=lnt>574
</span><span class=lnt>575
</span><span class=lnt>576
</span><span class=lnt>577
</span><span class=lnt>578
</span><span class=lnt>579
</span><span class=lnt>580
</span><span class=lnt>581
</span><span class=lnt>582
</span><span class=lnt>583
</span><span class=lnt>584
</span><span class=lnt>585
</span><span class=lnt>586
</span><span class=lnt>587
</span><span class=lnt>588
</span><span class=lnt>589
</span><span class=lnt>590
</span><span class=lnt>591
</span><span class=lnt>592
</span><span class=lnt>593
</span><span class=lnt>594
</span><span class=lnt>595
</span><span class=lnt>596
</span><span class=lnt>597
</span><span class=lnt>598
</span><span class=lnt>599
</span><span class=lnt>600
</span><span class=lnt>601
</span><span class=lnt>602
</span><span class=lnt>603
</span><span class=lnt>604
</span><span class=lnt>605
</span><span class=lnt>606
</span><span class=lnt>607
</span><span class=lnt>608
</span><span class=lnt>609
</span><span class=lnt>610
</span><span class=lnt>611
</span><span class=lnt>612
</span><span class=lnt>613
</span><span class=lnt>614
</span><span class=lnt>615
</span><span class=lnt>616
</span><span class=lnt>617
</span><span class=lnt>618
</span><span class=lnt>619
</span><span class=lnt>620
</span><span class=lnt>621
</span><span class=lnt>622
</span><span class=lnt>623
</span><span class=lnt>624
</span><span class=lnt>625
</span><span class=lnt>626
</span><span class=lnt>627
</span><span class=lnt>628
</span><span class=lnt>629
</span><span class=lnt>630
</span><span class=lnt>631
</span><span class=lnt>632
</span><span class=lnt>633
</span><span class=lnt>634
</span><span class=lnt>635
</span><span class=lnt>636
</span><span class=lnt>637
</span><span class=lnt>638
</span><span class=lnt>639
</span><span class=lnt>640
</span><span class=lnt>641
</span><span class=lnt>642
</span><span class=lnt>643
</span><span class=lnt>644
</span><span class=lnt>645
</span><span class=lnt>646
</span><span class=lnt>647
</span><span class=lnt>648
</span><span class=lnt>649
</span><span class=lnt>650
</span><span class=lnt>651
</span><span class=lnt>652
</span><span class=lnt>653
</span><span class=lnt>654
</span><span class=lnt>655
</span><span class=lnt>656
</span><span class=lnt>657
</span><span class=lnt>658
</span><span class=lnt>659
</span><span class=lnt>660
</span><span class=lnt>661
</span><span class=lnt>662
</span><span class=lnt>663
</span><span class=lnt>664
</span><span class=lnt>665
</span><span class=lnt>666
</span><span class=lnt>667
</span><span class=lnt>668
</span><span class=lnt>669
</span><span class=lnt>670
</span><span class=lnt>671
</span><span class=lnt>672
</span><span class=lnt>673
</span><span class=lnt>674
</span><span class=lnt>675
</span><span class=lnt>676
</span><span class=lnt>677
</span><span class=lnt>678
</span><span class=lnt>679
</span><span class=lnt>680
</span><span class=lnt>681
</span><span class=lnt>682
</span><span class=lnt>683
</span><span class=lnt>684
</span><span class=lnt>685
</span><span class=lnt>686
</span><span class=lnt>687
</span><span class=lnt>688
</span><span class=lnt>689
</span><span class=lnt>690
</span><span class=lnt>691
</span><span class=lnt>692
</span><span class=lnt>693
</span><span class=lnt>694
</span><span class=lnt>695
</span><span class=lnt>696
</span><span class=lnt>697
</span><span class=lnt>698
</span><span class=lnt>699
</span><span class=lnt>700
</span><span class=lnt>701
</span><span class=lnt>702
</span><span class=lnt>703
</span><span class=lnt>704
</span><span class=lnt>705
</span><span class=lnt>706
</span><span class=lnt>707
</span><span class=lnt>708
</span><span class=lnt>709
</span><span class=lnt>710
</span><span class=lnt>711
</span><span class=lnt>712
</span><span class=lnt>713
</span><span class=lnt>714
</span><span class=lnt>715
</span><span class=lnt>716
</span><span class=lnt>717
</span><span class=lnt>718
</span><span class=lnt>719
</span><span class=lnt>720
</span><span class=lnt>721
</span><span class=lnt>722
</span><span class=lnt>723
</span><span class=lnt>724
</span><span class=lnt>725
</span><span class=lnt>726
</span><span class=lnt>727
</span><span class=lnt>728
</span><span class=lnt>729
</span><span class=lnt>730
</span><span class=lnt>731
</span><span class=lnt>732
</span><span class=lnt>733
</span><span class=lnt>734
</span><span class=lnt>735
</span><span class=lnt>736
</span><span class=lnt>737
</span><span class=lnt>738
</span><span class=lnt>739
</span><span class=lnt>740
</span><span class=lnt>741
</span><span class=lnt>742
</span><span class=lnt>743
</span><span class=lnt>744
</span><span class=lnt>745
</span><span class=lnt>746
</span><span class=lnt>747
</span><span class=lnt>748
</span><span class=lnt>749
</span><span class=lnt>750
</span><span class=lnt>751
</span><span class=lnt>752
</span><span class=lnt>753
</span><span class=lnt>754
</span><span class=lnt>755
</span><span class=lnt>756
</span><span class=lnt>757
</span><span class=lnt>758
</span><span class=lnt>759
</span><span class=lnt>760
</span><span class=lnt>761
</span><span class=lnt>762
</span><span class=lnt>763
</span><span class=lnt>764
</span><span class=lnt>765
</span><span class=lnt>766
</span><span class=lnt>767
</span><span class=lnt>768
</span><span class=lnt>769
</span><span class=lnt>770
</span><span class=lnt>771
</span><span class=lnt>772
</span><span class=lnt>773
</span><span class=lnt>774
</span><span class=lnt>775
</span><span class=lnt>776
</span><span class=lnt>777
</span><span class=lnt>778
</span><span class=lnt>779
</span><span class=lnt>780
</span><span class=lnt>781
</span><span class=lnt>782
</span><span class=lnt>783
</span><span class=lnt>784
</span><span class=lnt>785
</span><span class=lnt>786
</span><span class=lnt>787
</span><span class=lnt>788
</span><span class=lnt>789
</span><span class=lnt>790
</span><span class=lnt>791
</span><span class=lnt>792
</span><span class=lnt>793
</span><span class=lnt>794
</span><span class=lnt>795
</span><span class=lnt>796
</span><span class=lnt>797
</span><span class=lnt>798
</span><span class=lnt>799
</span><span class=lnt>800
</span><span class=lnt>801
</span><span class=lnt>802
</span><span class=lnt>803
</span><span class=lnt>804
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>random</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>copy</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pdb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.nn.utils.rnn</span> <span class=kn>import</span> <span class=n>pad_sequence</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForCausalLM</span><span class=p>,</span> <span class=n>AutoTokenizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span><span class=p>,</span> <span class=n>load_from_disk</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>set_random_seed</span><span class=p>(</span><span class=n>seed</span><span class=p>:</span> <span class=nb>int</span><span class=o>=</span><span class=mi>42</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>manual_seed_all</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>deterministic</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>benchmark</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>set_random_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;WANDB_API_KEY&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;YOUR_API_KEY&#34;</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;WANDB_PROJECT&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;GRPO-Qwen-2.5-1.5B-Instruct&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置系统prompt</span>
</span></span><span class=line><span class=cl><span class=n>SYSTEM_PROMPT</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Respond in the following format:
</span></span></span><span class=line><span class=cl><span class=s2>&lt;reasoning&gt;
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>&lt;/reasoning&gt;
</span></span></span><span class=line><span class=cl><span class=s2>&lt;answer&gt;
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>&lt;/answer&gt;
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_answer_from_model_output</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>   Extracts the value from the last &lt;answer&gt; tag in the text.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Args:
</span></span></span><span class=line><span class=cl><span class=s2>       text (str): The model-generated text containing XML-style &lt;answer&gt; tags.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       str or None: The content inside the &lt;answer&gt; tags, or None if no valid answer is found.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Splits the text on the &lt;answer&gt; tag to isolate content after the tag.
</span></span></span><span class=line><span class=cl><span class=s2>       2. Checks if at least one &lt;answer&gt; tag exists in the text.
</span></span></span><span class=line><span class=cl><span class=s2>       3. For the last &lt;answer&gt; segment:
</span></span></span><span class=line><span class=cl><span class=s2>          - Verifies it contains a closing &lt;/answer&gt; tag.
</span></span></span><span class=line><span class=cl><span class=s2>          - Extracts only the content between the tags.
</span></span></span><span class=line><span class=cl><span class=s2>       4. Returns None if the answer is empty (just &#34;...&#34;) or if tags are missing.
</span></span></span><span class=line><span class=cl><span class=s2>   &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>parts</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;&lt;answer&gt;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>parts</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>:</span> <span class=c1># No &lt;answer&gt; tag found</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=n>last_part</span> <span class=o>=</span> <span class=n>parts</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s1>&#39;&lt;/answer&gt;&#39;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>last_part</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=n>answer</span> <span class=o>=</span> <span class=n>last_part</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;&lt;/answer&gt;&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=kc>None</span> <span class=k>if</span> <span class=n>answer</span> <span class=o>==</span> <span class=s2>&#34;...&#34;</span> <span class=k>else</span> <span class=n>answer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_answer_from_dataset</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>   Extracts the answer from the GSM8K dataset examples.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Args:
</span></span></span><span class=line><span class=cl><span class=s2>       text (str): The dataset example text containing a question and answer.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       str or None: The extracted answer part after the &#39;####&#39; delimiter, or None if not found.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Checks if the text contains the &#39;####&#39; delimiter that separates question from answer.
</span></span></span><span class=line><span class=cl><span class=s2>       2. If found, splits the text at this delimiter and returns the second part (the answer).
</span></span></span><span class=line><span class=cl><span class=s2>       3. The answer is stripped of leading/trailing whitespace.
</span></span></span><span class=line><span class=cl><span class=s2>       4. Returns None if no delimiter is present.
</span></span></span><span class=line><span class=cl><span class=s2>   &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;####&#34;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>text</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;####&#34;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>prepare_dataset</span><span class=p>(</span><span class=n>split</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>   Load and prepare the GSM8K dataset for training with string prompts.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Args:
</span></span></span><span class=line><span class=cl><span class=s2>       split (str): The dataset split to load (&#34;train&#34; or &#34;test&#34;). Defaults to &#34;train&#34;.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       list: A list of formatted examples, each containing a prompt string and answer.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Loads the GSM8K dataset from the Hugging Face datasets hub.
</span></span></span><span class=line><span class=cl><span class=s2>       2. For each example in the dataset:
</span></span></span><span class=line><span class=cl><span class=s2>          - Creates a list of messages with system prompt and the question.
</span></span></span><span class=line><span class=cl><span class=s2>          - Converts this list into a single string prompt using build_prompt().
</span></span></span><span class=line><span class=cl><span class=s2>          - Extracts the answer from the dataset example.
</span></span></span><span class=line><span class=cl><span class=s2>          - Creates a formatted example dictionary with prompt and answer.
</span></span></span><span class=line><span class=cl><span class=s2>       3. Returns the list of formatted examples ready for model training or evaluation.
</span></span></span><span class=line><span class=cl><span class=s2>   &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 从本地加载，服务器端连接不上huggingface，使用train部分的数据</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>load_from_disk</span><span class=p>(</span><span class=s1>&#39;/data/ztq147/gsm8k&#39;</span><span class=p>)[</span><span class=n>split</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># data = load_dataset(&#39;openai/gsm8k&#39;, &#39;main&#39;)[split]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 一个formatted数据包含“prompt”和“answer”，其中“prompt”格式为SYSTEM_PROMPT\n QUESTION；“answer”格式为ANSWER</span>
</span></span><span class=line><span class=cl>    <span class=n>formatted_data</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>example</span> <span class=ow>in</span> <span class=n>data</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_str</span> <span class=o>=</span> <span class=n>build_prompt</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>SYSTEM_PROMPT</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>example</span><span class=p>[</span><span class=s1>&#39;question&#39;</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>            <span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>formatted_example</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prompt&#34;</span><span class=p>:</span> <span class=n>prompt_str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;answer&#34;</span><span class=p>:</span> <span class=n>extract_answer_from_dataset</span><span class=p>(</span><span class=n>example</span><span class=p>[</span><span class=s2>&#34;answer&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>formatted_data</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>formatted_example</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>formatted_data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>build_prompt</span><span class=p>(</span><span class=n>messages</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>   Build a single prompt string from a list of messages.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Args:
</span></span></span><span class=line><span class=cl><span class=s2>       messages (list): A list of message dictionaries, each with &#39;role&#39; and &#39;content&#39; keys.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       str: A concatenated string of all message contents.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>   Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Takes a list of message dictionaries in the typical chat format.
</span></span></span><span class=line><span class=cl><span class=s2>       2. Extracts the &#39;content&#39; field from each message and strips whitespace.
</span></span></span><span class=line><span class=cl><span class=s2>       3. Joins all content strings with newlines to create a single prompt.
</span></span></span><span class=line><span class=cl><span class=s2>       4. This preserves the training format while converting from structured messages to a string.
</span></span></span><span class=line><span class=cl><span class=s2>   &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=n>msg</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=k>for</span> <span class=n>msg</span> <span class=ow>in</span> <span class=n>messages</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_last_number</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Extracts the last number appearing in the text.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>       text (str): The text to extract a number from.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       float or None: The last number in the text, or None if no number is found.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Removes dollar signs and percent symbols from the text.
</span></span></span><span class=line><span class=cl><span class=s2>       2. Uses regex to find a number that appears at the end of the text (possibly after whitespace).
</span></span></span><span class=line><span class=cl><span class=s2>       3. The pattern matches numbers that appear at the end of the string, with or without decimal points.
</span></span></span><span class=line><span class=cl><span class=s2>       4. Returns the found number as a float, or None if no match is found.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;$&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;%&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pattern</span> <span class=o>=</span> <span class=sa>r</span><span class=s1>&#39;(?:^|\s|=)\s*(-?\d*\.?\d+)\s*$&#39;</span>
</span></span><span class=line><span class=cl>    <span class=k>match</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>pattern</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>float</span><span class=p>(</span><span class=k>match</span><span class=o>.</span><span class=n>group</span><span class=p>(</span><span class=mi>1</span><span class=p>))</span> <span class=k>if</span> <span class=k>match</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_single_number</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Extracts the last number appearing in the text.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>       text (str): The text to extract a number from.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       float or None: The last number in the text, or None if no number is found.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Removes dollar signs and percent symbols from the text.
</span></span></span><span class=line><span class=cl><span class=s2>       2. Uses regex to find a number that appears at the end of the text (possibly after whitespace).
</span></span></span><span class=line><span class=cl><span class=s2>       3. The pattern matches numbers that appear at the end of the string, with or without decimal points.
</span></span></span><span class=line><span class=cl><span class=s2>       4. Returns the found number as a float, or None if no match is found.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;$&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;%&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pattern</span> <span class=o>=</span> <span class=sa>r</span><span class=s1>&#39;(?:^|\s|=)\s*(-?\d*\.?\d+)\s*$&#39;</span>
</span></span><span class=line><span class=cl>    <span class=k>match</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>pattern</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>float</span><span class=p>(</span><span class=k>match</span><span class=o>.</span><span class=n>group</span><span class=p>(</span><span class=mi>1</span><span class=p>))</span> <span class=k>if</span> <span class=k>match</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>eval_examples</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Evaluates the model on a set of examples and prints detailed results.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>       model: The language model to evaluate.
</span></span></span><span class=line><span class=cl><span class=s2>       tokenizer: The tokenizer for encoding inputs and decoding outputs.
</span></span></span><span class=line><span class=cl><span class=s2>       eval_examples (list): List of evaluation examples, each containing &#34;prompt&#34; and &#34;answer&#34;.
</span></span></span><span class=line><span class=cl><span class=s2>       device: The device (CPU or GPU) to run evaluation on.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       float: The accuracy percentage (correct predictions / total examples * 100).
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Sets the model to evaluation mode.
</span></span></span><span class=line><span class=cl><span class=s2>       2. For each example in the evaluation set:
</span></span></span><span class=line><span class=cl><span class=s2>          - Encodes the prompt and generates a response using the model.
</span></span></span><span class=line><span class=cl><span class=s2>          - Extracts the predicted answer from the generated response.
</span></span></span><span class=line><span class=cl><span class=s2>          - Compares the predicted answer with the expected answer using multiple methods:
</span></span></span><span class=line><span class=cl><span class=s2>            a. Exact string matching
</span></span></span><span class=line><span class=cl><span class=s2>            b. Single number extraction and comparison
</span></span></span><span class=line><span class=cl><span class=s2>            c. Last number extraction and comparison
</span></span></span><span class=line><span class=cl><span class=s2>          - Prints detailed information about each example.
</span></span></span><span class=line><span class=cl><span class=s2>       3. Calculates and returns the overall accuracy.
</span></span></span><span class=line><span class=cl><span class=s2>       4. Returns the model to training mode.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>total</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>eval_examples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;EVALUATION ON&#34;</span><span class=p>,</span> <span class=n>total</span><span class=p>,</span> <span class=s2>&#34;EXAMPLES&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>example</span> <span class=ow>in</span> <span class=n>eval_examples</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>full_prompt</span> <span class=o>=</span> <span class=n>example</span><span class=p>[</span><span class=s2>&#34;prompt&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>expected</span> <span class=o>=</span> <span class=n>example</span><span class=p>[</span><span class=s2>&#34;answer&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>full_prompt</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># early_stopping=False，表示模型会一直生直到达到最大新标记数（max_new_tokens）。</span>
</span></span><span class=line><span class=cl>        <span class=c1># forced_eos_token_id=tokenizer.eos_token_id，当生成到最大长度时，默认将最后一个token换成eos_token_id。</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>num_return_sequences</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>pad_token_id</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>eos_token_id</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>forced_eos_token_id</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>early_stopping</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>outputs</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 关于数学类问题评估的方法，这里不太了解，之前没做过</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>predicted</span> <span class=o>=</span> <span class=n>extract_answer_from_model_output</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>predicted</span> <span class=o>==</span> <span class=n>expected</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>is_correct</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>pred_num</span> <span class=o>=</span> <span class=n>extract_single_number</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>predicted</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                <span class=n>exp_num</span> <span class=o>=</span> <span class=n>extract_single_number</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>expected</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>pred_num</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>exp_num</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>pred_num</span> <span class=o>==</span> <span class=n>exp_num</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>is_correct</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>pred_num</span> <span class=o>=</span> <span class=n>extract_last_number</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>predicted</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                    <span class=n>exp_num</span> <span class=o>=</span> <span class=n>extract_last_number</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>expected</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                    <span class=n>is_correct</span> <span class=o>=</span> <span class=p>(</span><span class=n>pred_num</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>exp_num</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>pred_num</span> <span class=o>==</span> <span class=n>exp_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>is_correct</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>correct</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Prompt:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>full_prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Expected Answer:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>expected</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Extracted Answer:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>predicted</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Full Generated Response:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Correct:&#34;</span><span class=p>,</span> <span class=s2>&#34;✓&#34;</span> <span class=k>if</span> <span class=n>is_correct</span> <span class=k>else</span> <span class=s2>&#34;✗&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;-&#34;</span><span class=o>*</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Failed to parse model output for prompt:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>full_prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Error:&#34;</span><span class=p>,</span> <span class=n>e</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;-&#34;</span><span class=o>*</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>accuracy</span> <span class=o>=</span> <span class=p>(</span><span class=n>correct</span> <span class=o>/</span> <span class=n>total</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Accuracy: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>% (</span><span class=si>{</span><span class=n>correct</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>total</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>accuracy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>correctness_reward</span><span class=p>(</span><span class=n>prompts</span><span class=p>,</span> <span class=n>completions</span><span class=p>,</span> <span class=n>answer</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Assigns a reward based on the correctness of the model&#39;s answer.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    prompts (list): List of input prompts.
</span></span></span><span class=line><span class=cl><span class=s2>    completions (list): List of model completions, each containing content.
</span></span></span><span class=line><span class=cl><span class=s2>    answer (list): List of expected answers.
</span></span></span><span class=line><span class=cl><span class=s2>    **kwargs: Additional keyword arguments.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    list: List of numerical rewards for each completion.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>    1. Extracts the content from each completion.
</span></span></span><span class=line><span class=cl><span class=s2>    2. Extracts the answer portion from each response using extract_answer_from_model_output.
</span></span></span><span class=line><span class=cl><span class=s2>    3. Assigns rewards based on matching criteria:
</span></span></span><span class=line><span class=cl><span class=s2>      - 2.0 points for an exact match
</span></span></span><span class=line><span class=cl><span class=s2>      - 1.5 points for numeric equivalence (when values match but format differs)
</span></span></span><span class=line><span class=cl><span class=s2>      - 0.0 points for incorrect answers
</span></span></span><span class=line><span class=cl><span class=s2>    4. Tracks completion lengths for analysis.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>responses</span> <span class=o>=</span> <span class=p>[</span><span class=n>completion</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;content&#39;</span><span class=p>]</span> <span class=k>for</span> <span class=n>completion</span> <span class=ow>in</span> <span class=n>completions</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>extracted</span> <span class=o>=</span> <span class=p>[</span><span class=n>extract_answer_from_model_output</span><span class=p>(</span><span class=n>r</span><span class=p>)</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>responses</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>rewards</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>r</span><span class=p>,</span> <span class=n>a</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>extracted</span><span class=p>,</span> <span class=n>answer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>r</span> <span class=o>==</span> <span class=n>a</span><span class=p>:</span> <span class=c1># Exact match case</span>
</span></span><span class=line><span class=cl>            <span class=n>rewards</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=mf>2.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>r_num</span> <span class=o>=</span> <span class=n>extract_single_number</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>r</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>a_num</span> <span class=o>=</span> <span class=n>extract_single_number</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>a</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>r_num</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>a_num</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>r_num</span> <span class=o>==</span> <span class=n>a_num</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>rewards</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=mf>1.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>rewards</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=mf>0.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>completion_lengths</span> <span class=o>=</span> <span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>split</span><span class=p>())</span> <span class=k>for</span> <span class=n>response</span> <span class=ow>in</span> <span class=n>responses</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>rewards</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>format_reward</span><span class=p>(</span><span class=n>completions</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Assigns a reward for adhering to the desired XML format.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>       completions (list): List of model completions, each containing content.
</span></span></span><span class=line><span class=cl><span class=s2>       **kwargs: Additional keyword arguments.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       list: List of format compliance scores for each completion.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Extracts the content from each completion.
</span></span></span><span class=line><span class=cl><span class=s2>       2. Evaluates format compliance by checking for required XML tags:
</span></span></span><span class=line><span class=cl><span class=s2>          - 0.2 points for each tag present (&lt;reasoning&gt;, &lt;/reasoning&gt;, &lt;answer&gt;, &lt;/answer&gt;)
</span></span></span><span class=line><span class=cl><span class=s2>          - Maximum score of 0.8 for perfect format compliance
</span></span></span><span class=line><span class=cl><span class=s2>       3. Stores and returns the format compliance scores.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>responses</span> <span class=o>=</span> <span class=p>[</span><span class=n>completion</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;content&#39;</span><span class=p>]</span> <span class=k>for</span> <span class=n>completion</span> <span class=ow>in</span> <span class=n>completions</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>rewards</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>format_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>response</span> <span class=ow>in</span> <span class=n>responses</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;&lt;reasoning&gt;&#34;</span> <span class=ow>in</span> <span class=n>response</span><span class=p>:</span> <span class=n>score</span> <span class=o>+=</span> <span class=mf>0.2</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;&lt;/reasoning&gt;&#34;</span> <span class=ow>in</span> <span class=n>response</span><span class=p>:</span> <span class=n>score</span> <span class=o>+=</span> <span class=mf>0.2</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;&lt;answer&gt;&#34;</span> <span class=ow>in</span> <span class=n>response</span><span class=p>:</span> <span class=n>score</span> <span class=o>+=</span> <span class=mf>0.2</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;&lt;/answer&gt;&#34;</span> <span class=ow>in</span> <span class=n>response</span><span class=p>:</span> <span class=n>score</span> <span class=o>+=</span> <span class=mf>0.2</span>
</span></span><span class=line><span class=cl>        <span class=n>rewards</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>score</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>format_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>score</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>rewards</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>combined_reward</span><span class=p>(</span><span class=n>prompts</span><span class=p>,</span> <span class=n>completions</span><span class=p>,</span> <span class=n>answer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Combines correctness and format rewards.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>       prompts (list[str]): List of prompt texts
</span></span></span><span class=line><span class=cl><span class=s2>       completions (list[list[dict]]): List of completion dictionaries
</span></span></span><span class=line><span class=cl><span class=s2>       answer (list[str]): List of expected answers
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>       list[float]: Combined rewards for each prompt-completion pair
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>       1. Calculates separate rewards for correctness and format compliance.
</span></span></span><span class=line><span class=cl><span class=s2>       2. Combines the rewards with the following weights:
</span></span></span><span class=line><span class=cl><span class=s2>          - Correctness score range: 0.0 to 2.0
</span></span></span><span class=line><span class=cl><span class=s2>          - Format score range: 0.0 to 0.8
</span></span></span><span class=line><span class=cl><span class=s2>          - Total possible range: 0.0 to 2.8
</span></span></span><span class=line><span class=cl><span class=s2>       3. Returns the combined reward for each example.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># Get individual rewards</span>
</span></span><span class=line><span class=cl>    <span class=n>correctness_scores</span> <span class=o>=</span> <span class=n>correctness_reward</span><span class=p>(</span><span class=n>prompts</span><span class=o>=</span><span class=n>prompts</span><span class=p>,</span> <span class=n>completions</span><span class=o>=</span><span class=n>completions</span><span class=p>,</span> <span class=n>answer</span><span class=o>=</span><span class=n>answer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>format_scores</span> <span class=o>=</span> <span class=n>format_reward</span><span class=p>(</span><span class=n>completions</span><span class=o>=</span><span class=n>completions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Combine rewards - correctness is weighted more heavily</span>
</span></span><span class=line><span class=cl>    <span class=n>combined_rewards</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>c_score</span><span class=p>,</span> <span class=n>f_score</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>correctness_scores</span><span class=p>,</span> <span class=n>format_scores</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Correctness score range: 0.0 to 2.0</span>
</span></span><span class=line><span class=cl>        <span class=c1># Format score range: 0.0 to 0.8</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total range: 0.0 to 2.8</span>
</span></span><span class=line><span class=cl>        <span class=n>combined_rewards</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>c_score</span> <span class=o>+</span> <span class=n>f_score</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>combined_rewards</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>selective_log_softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>input_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Computes log probabilities for specific tokens in the vocabulary.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        logits (torch.Tensor): The raw logits output from the model.
</span></span></span><span class=line><span class=cl><span class=s2>        input_ids (torch.Tensor): The token IDs for which we want the log probabilities.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        torch.Tensor: Log probabilities of the selected tokens.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Applies log softmax to convert logits to log probabilities over the vocabulary.
</span></span></span><span class=line><span class=cl><span class=s2>        2. Uses gather to extract only the log probabilities corresponding to the input_ids.
</span></span></span><span class=line><span class=cl><span class=s2>        3. Removes the extra dimension to match the original shape of input_ids.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>log_probs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>log_probs</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=n>input_ids</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_log_probs</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span><span class=p>,</span> <span class=n>logits_to_keep</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Computes the log probabilities for a batch of tokens.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: The language model.
</span></span></span><span class=line><span class=cl><span class=s2>        input_ids (torch.Tensor): Token IDs for input sequences.
</span></span></span><span class=line><span class=cl><span class=s2>        attention_mask (torch.Tensor): Attention mask for input sequences.
</span></span></span><span class=line><span class=cl><span class=s2>        logits_to_keep (int): Number of tokens to keep from the end of the sequence.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        torch.Tensor: Log probabilities of the selected tokens.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Gets logits from the model for the input sequence.
</span></span></span><span class=line><span class=cl><span class=s2>        2. Selects logits for all tokens except the last one (as we predict next tokens).
</span></span></span><span class=line><span class=cl><span class=s2>        3. Selects only the last &#39;logits_to_keep&#39; tokens from both logits and input_ids.
</span></span></span><span class=line><span class=cl><span class=s2>        4. Computes log probabilities for these tokens using selective_log_softmax.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>logits</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span><span class=o>=</span><span class=n>attention_mask</span><span class=p>)</span><span class=o>.</span><span class=n>logits</span><span class=p>[:,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>    <span class=n>input_ids</span> <span class=o>=</span> <span class=n>input_ids</span><span class=p>[:,</span> <span class=o>-</span><span class=n>logits_to_keep</span><span class=p>:]</span>  <span class=c1># select the generation part, remove the prompt part</span>
</span></span><span class=line><span class=cl>    <span class=n>logits</span> <span class=o>=</span> <span class=n>logits</span><span class=p>[:,</span> <span class=o>-</span><span class=n>logits_to_keep</span><span class=p>:,</span> <span class=p>:]</span>     <span class=c1># the same as input_ids</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>selective_log_softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>input_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_completion_mask</span><span class=p>(</span><span class=n>completion_ids</span><span class=p>,</span> <span class=n>eos_token_id</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Creates a mask for completion tokens that excludes tokens after the EOS token.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        completion_ids (torch.Tensor): Token IDs of the generated completions.
</span></span></span><span class=line><span class=cl><span class=s2>        eos_token_id (int): The ID of the end-of-sequence token.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        torch.Tensor: A binary mask with 1s for valid tokens and 0s after the EOS token.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Identifies positions where EOS tokens occur in each sequence.
</span></span></span><span class=line><span class=cl><span class=s2>        2. Finds the index of the first EOS token in each sequence.
</span></span></span><span class=line><span class=cl><span class=s2>        3. Creates a mask where positions before and including the first EOS are 1, others are 0.
</span></span></span><span class=line><span class=cl><span class=s2>        4. If no EOS token is found in a sequence, all positions are set to 1.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>is_eos</span> <span class=o>=</span> <span class=n>completion_ids</span> <span class=o>==</span> <span class=n>eos_token_id</span> <span class=c1># shape (bs, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>eos_idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>full</span><span class=p>((</span><span class=n>is_eos</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),),</span> <span class=n>is_eos</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>completion_ids</span><span class=o>.</span><span class=n>device</span><span class=p>)</span> <span class=c1># 表示每个completion的第一个Eos_token的位置，初始化全为max_completion_length. shape (bs, )</span>
</span></span><span class=line><span class=cl>    <span class=n>mask_exists</span> <span class=o>=</span> <span class=n>is_eos</span><span class=o>.</span><span class=n>any</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=c1># 返回一个布尔向量 shape (bs, )，表示哪些序列包含至少一个Eos token</span>
</span></span><span class=line><span class=cl>    <span class=n>eos_idx</span><span class=p>[</span><span class=n>mask_exists</span><span class=p>]</span> <span class=o>=</span> <span class=n>is_eos</span><span class=o>.</span><span class=n>int</span><span class=p>()</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)[</span><span class=n>mask_exists</span><span class=p>]</span> <span class=c1># 对于包含Eos token的序列，找到第一个Eos token的位置，is_eos.int().argmax(dim=1)返回每个序列中第一个Eos token的索引。</span>
</span></span><span class=line><span class=cl>    <span class=n>sequence_indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>is_eos</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=n>completion_ids</span><span class=o>.</span><span class=n>device</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>is_eos</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># shape (bs, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>sequence_indices</span> <span class=o>&lt;=</span> <span class=n>eos_idx</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>int</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_completions</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>prompts</span><span class=p>,</span> <span class=n>num_generations</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>max_completion_length</span><span class=o>=</span><span class=mi>32</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Generates multiple completions for each prompt.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: The language model.
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer: The tokenizer for encoding and decoding text.
</span></span></span><span class=line><span class=cl><span class=s2>        prompts (list): List of text prompts.
</span></span></span><span class=line><span class=cl><span class=s2>        num_generations (int): Number of completions to generate per prompt.
</span></span></span><span class=line><span class=cl><span class=s2>        max_completion_length (int): Maximum number of tokens to generate.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        tuple: Containing prompt IDs, prompt mask, completion IDs, and completion mask.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Encodes the prompts and moves them to the appropriate device.
</span></span></span><span class=line><span class=cl><span class=s2>        2. Repeats each prompt num_generations times to generate multiple completions.
</span></span></span><span class=line><span class=cl><span class=s2>        3. Generates completions using the model with specified parameters.
</span></span></span><span class=line><span class=cl><span class=s2>        4. Extracts the completion IDs (excluding the prompt tokens).
</span></span></span><span class=line><span class=cl><span class=s2>        5. Creates a mask for the completions using create_completion_mask.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda:0&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>prompts</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>padding_side</span><span class=o>=</span><span class=s2>&#34;left&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_mask</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Input batch size: </span><span class=si>{</span><span class=n>prompt_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2>, Device before model: </span><span class=si>{</span><span class=n>prompt_ids</span><span class=o>.</span><span class=n>device</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_length</span> <span class=o>=</span> <span class=n>prompt_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># .repeat_interleave 沿着dim=0重复num_generations次，使得prompt_ids和prompt_mask的维度都增加了num_generations倍</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids</span> <span class=o>=</span> <span class=n>prompt_ids</span><span class=o>.</span><span class=n>repeat_interleave</span><span class=p>(</span><span class=n>num_generations</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>   <span class=c1># shape (bs * num_generations, max_prompt_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_mask</span> <span class=o>=</span> <span class=n>prompt_mask</span><span class=o>.</span><span class=n>repeat_interleave</span><span class=p>(</span><span class=n>num_generations</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>   <span class=c1># shape (bs * num_generations, max_prompt_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_mask</span><span class=o>=</span><span class=n>prompt_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_new_tokens</span><span class=o>=</span><span class=n>max_completion_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>do_sample</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>pad_token_id</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>eos_token_id</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>early_stopping</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Output batch size: </span><span class=si>{</span><span class=n>outputs</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2>, Device after model: </span><span class=si>{</span><span class=n>outputs</span><span class=o>.</span><span class=n>device</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># completio_ids只包含模型生成的answer部分，长度为max_completion_length</span>
</span></span><span class=line><span class=cl>    <span class=n>completion_ids</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[:,</span> <span class=n>prompt_length</span><span class=p>:]</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>completion_mask</span> <span class=o>=</span> <span class=n>create_completion_mask</span><span class=p>(</span><span class=n>completion_ids</span><span class=p>,</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>prompt_ids</span><span class=p>,</span> <span class=n>prompt_mask</span><span class=p>,</span> <span class=n>completion_ids</span><span class=p>,</span> <span class=n>completion_mask</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_rollout_data</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>ref_model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>batch_samples</span><span class=p>,</span> <span class=n>num_generations</span><span class=p>,</span> <span class=n>max_completion_length</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Generates data for GRPO rollouts including completions and log probabilities.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: The policy model being trained.
</span></span></span><span class=line><span class=cl><span class=s2>        ref_model: The reference model for KL divergence calculation.
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer: The tokenizer for encoding and decoding text.
</span></span></span><span class=line><span class=cl><span class=s2>        batch_samples (list): Batch of training samples.
</span></span></span><span class=line><span class=cl><span class=s2>        num_generations (int): Number of completions to generate per sample.
</span></span></span><span class=line><span class=cl><span class=s2>        max_completion_length (int): Maximum completion length.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        dict: Dictionary containing all data needed for GRPO updates.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Extracts prompts and expected answers from the batch samples.
</span></span></span><span class=line><span class=cl><span class=s2>        2. Generates completions using the current policy model.
</span></span></span><span class=line><span class=cl><span class=s2>        3. Combines prompt and completion tokens.
</span></span></span><span class=line><span class=cl><span class=s2>        4. Computes log probabilities from both the policy model and reference model.
</span></span></span><span class=line><span class=cl><span class=s2>        5. Formats completions for reward calculation.
</span></span></span><span class=line><span class=cl><span class=s2>        6. Repeats prompts and answers to match the number of generated completions.
</span></span></span><span class=line><span class=cl><span class=s2>        7. Returns all data needed for GRPO loss calculation.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda:0&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompts</span> <span class=o>=</span> <span class=p>[</span><span class=n>sample</span><span class=p>[</span><span class=s2>&#34;prompt&#34;</span><span class=p>]</span> <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>sample</span><span class=p>,</span> <span class=nb>dict</span><span class=p>)</span> <span class=k>else</span> <span class=n>sample</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=k>for</span> <span class=n>sample</span> <span class=ow>in</span> <span class=n>batch_samples</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>answers</span> <span class=o>=</span> <span class=p>[</span><span class=n>sample</span><span class=p>[</span><span class=s2>&#34;answer&#34;</span><span class=p>]</span> <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>sample</span><span class=p>,</span> <span class=nb>dict</span><span class=p>)</span> <span class=k>else</span> <span class=n>sample</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>sample</span> <span class=ow>in</span> <span class=n>batch_samples</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span><span class=p>,</span> <span class=n>prompt_mask</span><span class=p>,</span> <span class=n>completion_ids</span><span class=p>,</span> <span class=n>completion_mask</span> <span class=o>=</span> <span class=n>generate_completions</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>prompts</span><span class=p>,</span> <span class=n>num_generations</span><span class=p>,</span> <span class=n>max_completion_length</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>input_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>completion_ids</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, max_prompt_length + max_completion_length)</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>prompt_mask</span><span class=p>,</span> <span class=n>completion_mask</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, max_prompt_length + max_completion_length)</span>
</span></span><span class=line><span class=cl>        <span class=n>logits_to_keep</span> <span class=o>=</span> <span class=n>completion_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># max_completion_length</span>
</span></span><span class=line><span class=cl>        <span class=n>old_log_probs</span> <span class=o>=</span> <span class=n>compute_log_probs</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span><span class=p>,</span> <span class=n>logits_to_keep</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>        <span class=n>ref_log_probs</span> <span class=o>=</span> <span class=n>compute_log_probs</span><span class=p>(</span><span class=n>ref_model</span><span class=p>,</span> <span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span><span class=p>,</span> <span class=n>logits_to_keep</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>formatted_completions</span> <span class=o>=</span> <span class=p>[[{</span><span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)}]</span> <span class=k>for</span> <span class=n>ids</span> <span class=ow>in</span> <span class=n>completion_ids</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>repeated_prompts</span> <span class=o>=</span> <span class=p>[</span><span class=n>p</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>prompts</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_generations</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>repeated_answers</span> <span class=o>=</span> <span class=p>[</span><span class=n>a</span> <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=n>answers</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_generations</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=n>input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>attention_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;completion_mask&#34;</span><span class=p>:</span> <span class=n>completion_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;old_log_probs&#34;</span><span class=p>:</span> <span class=n>old_log_probs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;ref_log_probs&#34;</span><span class=p>:</span> <span class=n>ref_log_probs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;formatted_completions&#34;</span><span class=p>:</span> <span class=n>formatted_completions</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;repeated_prompts&#34;</span><span class=p>:</span> <span class=n>repeated_prompts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;repeated_answers&#34;</span><span class=p>:</span> <span class=n>repeated_answers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;logits_to_keep&#34;</span><span class=p>:</span> <span class=n>logits_to_keep</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;batch_size&#34;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>prompts</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;num_generations&#34;</span><span class=p>:</span> <span class=n>num_generations</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>grpo_loss</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>ref_model</span><span class=p>,</span> <span class=n>rollout_data</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>reward_function</span><span class=p>,</span> <span class=n>beta</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Computes the GRPO loss for updating the policy model.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: The policy model being trained.
</span></span></span><span class=line><span class=cl><span class=s2>        ref_model: The reference model for KL divergence calculation.
</span></span></span><span class=line><span class=cl><span class=s2>        rollout_data (dict): Data generated by generate_rollout_data.
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer: The tokenizer for encoding and decoding text.
</span></span></span><span class=line><span class=cl><span class=s2>        reward_function: Function that calculates rewards for completions.
</span></span></span><span class=line><span class=cl><span class=s2>        beta (float): KL penalty coefficient.
</span></span></span><span class=line><span class=cl><span class=s2>        epsilon (float): Clipping parameter for PPO.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        torch.Tensor: The GRPO loss to be minimized.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Computes current token log probabilities using the policy model.
</span></span></span><span class=line><span class=cl><span class=s2>        2. Calculates the probability ratio between current and old policies.
</span></span></span><span class=line><span class=cl><span class=s2>        3. Computes rewards using the provided reward_function.
</span></span></span><span class=line><span class=cl><span class=s2>        4. Calculates advantages by standardizing rewards within each prompt.
</span></span></span><span class=line><span class=cl><span class=s2>        5. Computes the PPO surrogate objective with clipping.
</span></span></span><span class=line><span class=cl><span class=s2>        6. Calculates the KL divergence between reference and policy models.
</span></span></span><span class=line><span class=cl><span class=s2>        7. Combines surrogate loss and KL penalty.
</span></span></span><span class=line><span class=cl><span class=s2>        8. Averages the loss across all tokens and batches.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda:0&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>input_ids</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>completion_mask</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;completion_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>logits_to_keep</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;logits_to_keep&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>old_log_probs</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;old_log_probs&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>ref_log_probs</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;ref_log_probs&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>token_log_probs</span> <span class=o>=</span> <span class=n>compute_log_probs</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span><span class=p>,</span> <span class=n>logits_to_keep</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ratio</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>token_log_probs</span> <span class=o>-</span> <span class=n>old_log_probs</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>rewards</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>reward_function</span><span class=p>(</span><span class=n>prompts</span><span class=o>=</span><span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;repeated_prompts&#34;</span><span class=p>],</span> <span class=n>completions</span><span class=o>=</span><span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;formatted_completions&#34;</span><span class=p>],</span> <span class=n>answer</span><span class=o>=</span><span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;repeated_answers&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>        <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span><span class=o>=</span><span class=n>device</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>  <span class=c1># shape (bs * num_generations,)</span>
</span></span><span class=line><span class=cl>    <span class=c1>#print(f&#34;Rewards: {rewards}&#34;)  # Debug rewards</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;batch_size&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>num_generations</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=p>[</span><span class=s2>&#34;num_generations&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>rewards</span> <span class=o>=</span> <span class=n>rewards</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>num_generations</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_reward</span> <span class=o>=</span> <span class=n>rewards</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Average Reward:&#34;</span><span class=p>,</span> <span class=n>avg_reward</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mean_rewards</span> <span class=o>=</span> <span class=n>rewards</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>repeat_interleave</span><span class=p>(</span><span class=n>num_generations</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations,)</span>
</span></span><span class=line><span class=cl>    <span class=n>std_rewards</span> <span class=o>=</span> <span class=n>rewards</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>repeat_interleave</span><span class=p>(</span><span class=n>num_generations</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations,)</span>
</span></span><span class=line><span class=cl>    <span class=n>advantages</span> <span class=o>=</span> <span class=p>((</span><span class=n>rewards</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>-</span> <span class=n>mean_rewards</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>std_rewards</span> <span class=o>+</span> <span class=mf>1e-4</span><span class=p>))</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, 1)</span>
</span></span><span class=line><span class=cl>    <span class=n>surr1</span> <span class=o>=</span> <span class=n>ratio</span> <span class=o>*</span> <span class=n>advantages</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>surr2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>clamp</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>epsilon</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=n>epsilon</span><span class=p>)</span> <span class=o>*</span> <span class=n>advantages</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>surrogate_loss</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>surr1</span><span class=p>,</span> <span class=n>surr2</span><span class=p>)</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>kl</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>ref_log_probs</span> <span class=o>-</span> <span class=n>token_log_probs</span><span class=p>)</span> <span class=o>-</span> <span class=p>(</span><span class=n>ref_log_probs</span> <span class=o>-</span> <span class=n>token_log_probs</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>per_token_loss</span> <span class=o>=</span> <span class=n>surrogate_loss</span> <span class=o>-</span> <span class=n>beta</span> <span class=o>*</span> <span class=n>kl</span>  <span class=c1># shape (bs * num_generations, max_completion_length)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=o>-</span><span class=p>((</span><span class=n>per_token_loss</span> <span class=o>*</span> <span class=n>completion_mask</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>completion_mask</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># completion_mask用于把生成部分中eos token之后的部分mask掉，只保留生成部分的loss，其中每个completion都会对生成有效长度的loss进行平均，然后再对batch求平均，得到batch的loss。这里添加负号因为GRPO优化目标是最大化改值，这里用梯度下降来优化，所以这里加负号</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>loss</span><span class=p>,</span> <span class=n>avg_reward</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_with_grpo</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>train_data</span><span class=p>,</span> <span class=n>num_iterations</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_steps</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>num_generations</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>gradient_accumulation_steps</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>max_completion_length</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>beta</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>learning_rate</span><span class=o>=</span><span class=mf>5e-6</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>reward_function</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    This function is your original working code (train_with_grpo_static)
</span></span></span><span class=line><span class=cl><span class=s2>    with an added outer loop for iterative GRPO updates per the pseudocode.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: The language model to train.
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer: The tokenizer for encoding and decoding text.
</span></span></span><span class=line><span class=cl><span class=s2>        train_data (list): Training dataset.
</span></span></span><span class=line><span class=cl><span class=s2>        num_iterations (int): Number of outer iterations (reference model updates).
</span></span></span><span class=line><span class=cl><span class=s2>        num_steps (int): Number of batch updates per iteration.
</span></span></span><span class=line><span class=cl><span class=s2>        batch_size (int): Number of prompts per batch.
</span></span></span><span class=line><span class=cl><span class=s2>        num_generations (int): Number of completions per prompt.
</span></span></span><span class=line><span class=cl><span class=s2>        max_completion_length (int): Maximum token length for completions.
</span></span></span><span class=line><span class=cl><span class=s2>        beta (float): KL penalty coefficient.
</span></span></span><span class=line><span class=cl><span class=s2>        learning_rate (float): Learning rate for optimizer.
</span></span></span><span class=line><span class=cl><span class=s2>        mu (int): Number of policy updates per batch.
</span></span></span><span class=line><span class=cl><span class=s2>        epsilon (float): PPO clipping parameter.
</span></span></span><span class=line><span class=cl><span class=s2>        reward_function: Function that calculates rewards for completions.
</span></span></span><span class=line><span class=cl><span class=s2>        device_ids (list): List of GPU device IDs for DataParallel.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        The trained model.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. For each outer iteration:
</span></span></span><span class=line><span class=cl><span class=s2>           - Creates a reference model as a deep copy of the current policy model.
</span></span></span><span class=line><span class=cl><span class=s2>           - Reinitializes the optimizer for the policy model.
</span></span></span><span class=line><span class=cl><span class=s2>           - For each training step:
</span></span></span><span class=line><span class=cl><span class=s2>             a. Samples a batch of examples from the training data.
</span></span></span><span class=line><span class=cl><span class=s2>             b. Generates rollout data including completions and log probabilities.
</span></span></span><span class=line><span class=cl><span class=s2>             c. For mu iterations:
</span></span></span><span class=line><span class=cl><span class=s2>                i. Computes the GRPO loss.
</span></span></span><span class=line><span class=cl><span class=s2>                ii. Updates the policy model using gradient descent.
</span></span></span><span class=line><span class=cl><span class=s2>           - Monitors GPU memory usage and prints progress information.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># assert device_ids is not None and len(device_ids) &gt; 1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># device = torch.device(&#34;cuda:0&#34; if torch.cuda.is_available() else &#34;cpu&#34;)</span>
</span></span><span class=line><span class=cl>    <span class=c1># model = nn.DataParallel(model, device_ids=device_ids).cuda()</span>
</span></span><span class=line><span class=cl>    <span class=c1># print(f&#34;Model wrapped with DataParallel across GPUs: {device_ids}&#34;)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># num_iterations表示ref_model迭代次数</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_iterations</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Iteration </span><span class=si>{</span><span class=n>iteration</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>num_iterations</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Create a reference model (deep copy) and set it to eval mode.</span>
</span></span><span class=line><span class=cl>        <span class=n>ref_model</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ref_model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>ref_model</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Reference model created.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># pdb.set_trace()</span>
</span></span><span class=line><span class=cl>        <span class=c1># Inner loop: your original training steps.</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>num_steps</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_samples</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>train_data</span><span class=p>,</span> <span class=n>batch_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>                <span class=c1># 生成经验数据</span>
</span></span><span class=line><span class=cl>                <span class=n>rollout_data</span> <span class=o>=</span> <span class=n>generate_rollout_data</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>ref_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>batch_samples</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>num_generations</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>max_completion_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 对每批经验池数据学习的次数，一般设置mu=1</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>grpo_iter</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>mu</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>loss</span><span class=p>,</span> <span class=n>avg_reward</span> <span class=o>=</span> <span class=n>grpo_loss</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>ref_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>rollout_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>reward_function</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>beta</span><span class=o>=</span><span class=n>beta</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>epsilon</span><span class=o>=</span><span class=n>epsilon</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=p>(</span><span class=n>step</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>gradient_accumulation_steps</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;loss&#34;</span><span class=p>:</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;average_reward&#34;</span><span class=p>:</span> <span class=n>avg_reward</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;iteration&#34;</span><span class=p>:</span> <span class=n>iteration</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;step&#34;</span><span class=p>:</span> <span class=n>step</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;grpo_iter&#34;</span><span class=p>:</span> <span class=n>grpo_iter</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=p>})</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Iteration </span><span class=si>{</span><span class=n>iteration</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>num_iterations</span><span class=si>}</span><span class=s2>, Step </span><span class=si>{</span><span class=n>step</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>num_steps</span><span class=si>}</span><span class=s2>, &#34;</span>
</span></span><span class=line><span class=cl>                      <span class=sa>f</span><span class=s2>&#34;GRPO iter </span><span class=si>{</span><span class=n>grpo_iter</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>mu</span><span class=si>}</span><span class=s2>, loss: </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>optimize_model_memory</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Optimizes the model to use less memory during training.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: The language model to optimize.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        The optimized model.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Explanation:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Sets the model to training mode.
</span></span></span><span class=line><span class=cl><span class=s2>        2. Disables KV caching to save memory.
</span></span></span><span class=line><span class=cl><span class=s2>        3. Enables gradient checkpointing to trade computation for memory.
</span></span></span><span class=line><span class=cl><span class=s2>        4. Ensures that input embeddings require gradients:
</span></span></span><span class=line><span class=cl><span class=s2>           - Either uses the built-in method if available.
</span></span></span><span class=line><span class=cl><span class=s2>           - Or adds a forward hook to the input embeddings layer.
</span></span></span><span class=line><span class=cl><span class=s2>        5. Returns the optimized model ready for memory-efficient training.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>use_cache</span> <span class=o>=</span> <span class=kc>False</span>  <span class=c1># 不使用kv-cache缓存，减小显存消耗</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># First ensure inputs will require gradients</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;enable_input_require_grads&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>.</span><span class=n>enable_input_require_grads</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>make_inputs_require_grad</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=nb>input</span><span class=p>,</span> <span class=n>output</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>output</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>.</span><span class=n>get_input_embeddings</span><span class=p>()</span><span class=o>.</span><span class=n>register_forward_hook</span><span class=p>(</span><span class=n>make_inputs_require_grad</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Then enable gradient checkpointing</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>gradient_checkpointing_enable</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># Main execution</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda:0&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model_name</span> <span class=o>=</span> <span class=s2>&#34;/model/ztq147/Qwen/Qwen2.5-1.5B-Instruct&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span> <span class=o>=</span> <span class=s2>&#34;/data/ztq147/temp_models/math_solver_model&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>output_dir</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>output_dir</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Downloading model...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>device_map</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Model downloaded&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>padding_side</span><span class=o>=</span><span class=s2>&#34;left&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>pad_token_id</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>eos_token_id</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span>
</span></span><span class=line><span class=cl>    <span class=c1># setting the number of device</span>
</span></span><span class=line><span class=cl>    <span class=c1># device_ids = list(range(8))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>all_data</span> <span class=o>=</span> <span class=n>prepare_dataset</span><span class=p>(</span><span class=s2>&#34;train&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>random</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>all_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>size_of_eval_data</span> <span class=o>=</span> <span class=mi>30</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_data</span> <span class=o>=</span> <span class=n>all_data</span><span class=p>[:</span><span class=n>size_of_eval_data</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>train_data</span> <span class=o>=</span> <span class=n>all_data</span><span class=p>[</span><span class=n>size_of_eval_data</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># print(&#34;\nInital model evaluation before finetuning:&#34;)</span>
</span></span><span class=line><span class=cl>    <span class=c1># pre_grpo_accuracy = evaluate_model(model, tokenizer, eval_data, device)</span>
</span></span><span class=line><span class=cl>    <span class=c1># print(f&#34;Pre-GRPO Accuracy: {pre_grpo_accuracy:.2f}%&#34;)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>optimize_model_memory</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Starting RL fine-tuning using GRPO...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>training_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;num_iterations&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;num_steps&#39;</span><span class=p>:</span> <span class=mi>500</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;num_generations&#39;</span><span class=p>:</span> <span class=mi>8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;gradient_accumulation_steps&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;max_completion_length&#39;</span><span class=p>:</span> <span class=mi>256</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;beta&#39;</span><span class=p>:</span> <span class=mf>0.04</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;learning_rate&#39;</span><span class=p>:</span> <span class=mf>5e-6</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;mu&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;epsilon&#39;</span><span class=p>:</span> <span class=mf>0.1</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>init</span><span class=p>(</span><span class=n>project</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;WANDB_PROJECT&#34;</span><span class=p>],</span> <span class=n>reinit</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Weights &amp; Biases initialized.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># pdb.set_trace()</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>train_with_grpo</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_data</span><span class=o>=</span><span class=n>train_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>reward_function</span><span class=o>=</span><span class=n>combined_reward</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=c1># device_ids=device_ids,</span>
</span></span><span class=line><span class=cl>        <span class=o>**</span><span class=n>training_config</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>finish</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Training completed and wandb run finished.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Finalmodel evaluation after GTPO RL fine-tuning:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>post_grpo_accuracy</span> <span class=o>=</span> <span class=n>evaluate_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>eval_data</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Post-GRPO Accuracy: </span><span class=si>{</span><span class=n>post_grpo_accuracy</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Saving GTPO fine-tuned model...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>output_dir</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>output_dir</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=单卡实验结果>单卡实验结果<a hidden class=anchor aria-hidden=true href=#单卡实验结果>#</a></h3><p>作者使用一张3090GPU训练，实验结果如下：</p><ul><li>batch_size=2, num_generations=8, max_completion_length=256, gradient_accumulation_steps=1, mu=3, num_steps=500, num_iterations=1, beta=0.04, learning_rate=5e-6, epsilon=0.1</li></ul><p>最终的测试准确率：Accuracy: 23.33% (7/30)</p><p>这里横轴是1500步因为设置了mu=3，所以每个step被记录了三次，这个实验主要想看看mu的影响，个人理解mu=1的情况下，ratio的计算结果应该永远是1。</p><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image1.jpg alt=loss曲线></p><div align=center style=color:#999></div><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image2.jpg alt=reward曲线></p><div align=center style=color:#999></div><ul><li>batch_size=1, num_generations=8, max_completion_length=400, gradient_accumulation_steps=12, mu=1, num_steps=1500, num_iterations=1, beta=0.04, learning_rate=5e-6, epsilon=0.1</li></ul><p>最终的测试准确率：Accuracy: 36.67% (11/30)</p><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image3.jpg alt=loss曲线></p><div align=center style=color:#999></div><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image4.jpg alt=reward曲线></p><div align=center style=color:#999></div><ul><li>batch_size=2, num_generations=8, max_completion_length=256, gradient_accumulation_steps=6, mu=1, num_steps=500, num_iterations=1, beta=0.04, learning_rate=5e-6, epsilon=0.1</li></ul><p>最终的测试准确率：Accuracy: 40.00% (12/30)</p><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image5.jpg alt=loss曲线></p><div align=center style=color:#999></div><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image6.jpg alt=reward曲线></p><div align=center style=color:#999></div><ul><li>batch_size=2, num_generations=8, max_completion_length=256, gradient_accumulation_steps=1, mu=1, num_steps=500, num_iterations=1, beta=0.04, learning_rate=5e-6, epsilon=0.1</li></ul><p>最终的测试准确率：Accuracy: 46.67% (14/30)</p><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image7.jpg alt=loss曲线></p><div align=center style=color:#999></div><p><img loading=lazy src=/my-blog/images/2025-03-05-grpo/2025-03-05-image8.jpg alt=reward曲线></p><div align=center style=color:#999></div><h3 id=单卡实验小结>单卡实验小结<a hidden class=anchor aria-hidden=true href=#单卡实验小结>#</a></h3><p>从上面简单的几次实验结果来看，最好的是batch_size=2, num_generations=8, max_completion_length=256, gradient_accumulation_steps=1, mu=1, num_steps=500, num_iterations=1, beta=0.04, learning_rate=5e-6, epsilon=0.1，准确率达到了46.67%，但是这个结果与原作者的90%的准确率有较大差距，原作者用8张80G显存的A100，batch_size设置为7（一张卡放1条数据，原文用了数据并行nn.DataParallel），最大生成长度设置为400，num_generations设置为12，mu=1，gradient_accumulation_steps=1，一共训练500步，其他参数与本文这个设置的其他参数一致。</p><p>整体看对结果影响较大的参数有max_completino_length和num_generations。相反，设置gradient_accumulation_steps并没能带来大batch_size的效果（这个不确定是不是代码写的有问题），反而降低性能，mu的设置大于1也降低了性能。</p><p>实验的loss曲线也没有原文那种稳定的上升趋势，虽然不理解为啥loss是上升的，本文贴的所有loss图均是设置了最大Y值，实际上会存在很多loss很高的脉冲（十几到几百），这个脉冲存在的原因也不太清楚。reward图和原文的有一定相似性。</p><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><p>[1] Shao et al. <a href=https://arxiv.org/abs/2402.03300 class=entityLink>“DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models”</a> arXiv preprint arXiv:2402.03300 (2024).</p><p>[2] John Schulman. <a href=http://joschu.net/blog/kl-approx.html class=entityLink>“Approximating KL Divergence”</a> John Schulman&rsquo;s Homepage 2020.</p><p>[3] Andriy Burkov. <a href=https://github.com/aburkov/theLMbook/blob/main/GRPO_From_Scratch_Multi_GPU_DataParallel_Qwen_2_5_1_5B_Instruct.ipynb class=entityLink>“Coding GRPO from Scratch: A Guide to Distributed Implementation with Qwen2.5-1.5B-Instruct”</a> github 2025.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://tqzhong.github.io/my-blog/tags/ai/>AI</a></li><li><a href=https://tqzhong.github.io/my-blog/tags/nlp/>NLP</a></li><li><a href=https://tqzhong.github.io/my-blog/tags/llm/>LLM</a></li><li><a href=https://tqzhong.github.io/my-blog/tags/rl/>RL</a></li></ul><nav class=paginav><a class=prev href=https://tqzhong.github.io/my-blog/posts/2025-03-19-llm-post-training-via-reinforcement-learning/><span class=title>« Prev</span><br><span>大模型post-training方法——强化学习篇</span>
</a><a class=next href=https://tqzhong.github.io/my-blog/posts/2025-01-29-deepseek-v3/><span class=title>Next »</span><br><span>DeepSeek-V3技术报告解读</span></a></nav></footer></article><div class=social-icons><a href=https://github.com/tqzhong target=_blank rel="noopener noreferrer"><i class="fab fa-github"></i>
</a><a href=https://x.com/rs1047g target=_blank rel="noopener noreferrer"><i class="fab fa-twitter"></i>
</a><a href="https://scholar.google.com/citations?hl=en&amp;user=UNNLJX4AAAAJ" target=_blank rel="noopener noreferrer"><i class="fab fa-google"></i>
</a><a href=https://tqzhong.github.io target=_blank rel="noopener noreferrer"><i class="fas fa-user"></i></a></div><script src=https://utteranc.es/client.js repo=tqzhong/my-blog issue-term=pathname label=hugo-comment theme=github-dark crossorigin=anonymous async></script></main><footer class=footer><span>&copy; 2025 <a href=https://tqzhong.github.io/my-blog/>Rs' Log</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script src=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js></script><script src=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}]})})</script></body></html>