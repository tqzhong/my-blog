<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Deepspeed on Rs' Log</title><link>https://tqzhong.github.io/my-blog/tags/deepspeed/</link><description>Recent content in Deepspeed on Rs' Log</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 30 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://tqzhong.github.io/my-blog/tags/deepspeed/index.xml" rel="self" type="application/rss+xml"/><item><title>Deepspeed多机多卡训练&amp;代码细节</title><link>https://tqzhong.github.io/my-blog/posts/2024-10-30-deepspeed/</link><pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate><guid>https://tqzhong.github.io/my-blog/posts/2024-10-30-deepspeed/</guid><description>&lt;p>本次使用的是多台8卡1080Ti服务器进行DeepSpeed多机多卡实验。&lt;/p>
&lt;h3 id="supervised-finetuning">Supervised finetuning&lt;/h3>
&lt;p>首先在主节点克隆&lt;a href="https://github.com/microsoft/DeepSpeedExamples" class="entityLink">deepspeed-chat&lt;/a>仓库。&lt;/p>
&lt;p>使用的主要环境：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">pip install &lt;span class="nv">torch&lt;/span>&lt;span class="o">==&lt;/span>1.13.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install datasets
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install sentencepiece
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install &lt;span class="nv">protobuf&lt;/span>&lt;span class="o">==&lt;/span>3.20.3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install accelerate
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install &lt;span class="nv">deepspeed&lt;/span>&lt;span class="o">==&lt;/span>0.10.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install &lt;span class="nv">transformers&lt;/span>&lt;span class="o">==&lt;/span>4.44.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install tensorboard
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install &lt;span class="nv">numpy&lt;/span>&lt;span class="o">==&lt;/span>1.26.4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>deepspeed安装需要有nvcc，开始这些1080Ti服务器没有nvcc，所以先装了这个：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">sudo apt update
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sudo apt install nvidia-cuda-toolkit
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>之后先跑通单节点，我用的是&lt;code>step1_supervised_finetuning/training_scripts/opt/single_node/run_1.3b.sh&lt;/code>，因为当时考虑1080Ti显存较小，不过后来发现原仓库里的bash脚本都差不多，就是改了模型路径。&lt;/p>
&lt;p>跑通单节点也花了不少时间，最开始是模型和数据集的问题，因为服务器本地连接不到hf，所以下载了opt-1.3b模型到主节点，数据集部分也无法访问hf，是从hf上下载了&lt;code>synthetic-instruct-gptj-pairwise&lt;/code>数据集，两个文件保存在主节点：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">datasets
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> └── synthetic-instruct-gptj-pairwise
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ├── dataset_infos.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> └── train-00000-of-00001-1e5d57b93c448e7a.parquet
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在&lt;code>dschat/utils/data/raw_datasets.py&lt;/code>的数据集类&lt;code>PromptRawDataset&lt;/code>上也做了对应修改:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">PromptRawDataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">object&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">output_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">seed&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">local_rank&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dataset_name&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">output_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">output_path&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">seed&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">seed&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">local_rank&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">local_rank&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;原始数据的读取，这里根据自己数据集作相应修改&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">raw_datasets&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">load_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;parquet&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data_files&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">dataset_name&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>到这里，数据集模型以及环境都差不多了，在单节点上启动训练脚本，发现optimizer有报错，原因是原训练主函数使用的是&lt;code>FusedAdam&lt;/code>，可能是g++环境匹配存在问题，这个最终没解决就没管了，直接把optimizer换成&lt;code>AdamW&lt;/code>就跑通了。查了一下&lt;code>FusedAdam&lt;/code>在需要大量计算资源的场景下有一定优势。&lt;/p></description></item></channel></rss>